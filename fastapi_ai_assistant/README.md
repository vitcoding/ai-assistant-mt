# ИИ Ассистент для онлайн кинотеатра

## Описание.
В сервисе реализован чат с ИИ Ассистентом, который отвечает на вопросы и имеет возможность подкреплять ответы данными о фильмах на основе RAG (Retrieval Augmented Generation).

В чате поддерживается ввод текста и отправка голосовых сообщений.

При создании нового чата доступны:
- выбор модели LLM;
- выбор языка, на котором будет отвечать ИИ Ассистент;
- включение / отключение RAG;
- включение / отключение озвучивания сообщений ИИ Ассистента.

После запуска сервиса чат доступен по ссылке:
[http://localhost:8005/api/v1/chat_ai/](http://localhost:8005/api/v1/chat_ai/)

**Для доступа к чату требуется авторизация** в [сервисе авторизации](../fastapi_auth/README.md).
По умолчанию в сервисе авторизации создается пользователь с логином "admin" и паролем "admin".

### Архитектурное решение:
- **серверная часть**: сервер на Fast API для обработки запросов пользователей, взаимодействия с LLM на основе фреймворка LangChain, обработки голосовых сообщений ввода при помощи Faster-Whisper;
- **key-value хранилище**: Redis для хранения ссылок на аудиофайлы при использовании голосового управления в чате;
- **сервис LLM**: Ollama для использования локальной LLM;
- **векторное хранилище**: Chroma db для хранения данных о фильмах в векторном представлении при использовании сценария с RAG;
- **документация OpenAPI**: встроенная автоматически генерируемая документация FastAPI на основе спецификаций OpenAPI.

### Тесты.
Сделаны тесты для проверки работоспособности эндпоинтa чата.

### Основные команды для запуска сервиса:
- **запуск сервиса в docker compose**: 
`docker compose -f docker-compose-ai.yml up -d`;
- **остановка сервиса**: 
`docker compose -f docker-compose-ai.yml down`;
- **запуск тестов**: 
`docker compose -f src/tests/docker-compose.yml up -d`;
- **завершение тестов**: 
`docker compose -f src/tests/docker-compose.yml down -v`.

### Документация OpenAPI
[http://localhost:8005/api/openapi](http://localhost:8005/api/openapi)